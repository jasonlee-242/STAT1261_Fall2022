trControl=trControl,
metric = "Accuracy")
key <- toString(mtry)
accuracy[[key]] <- fit
}
trControl <- trainControl(method="repeatedcv", number=5, repeats=2)
accuracy <- list()
for (mtry in seq(2,20,2)){
tunegrid = expand.grid(.mtry = mtry)
fit <- train(y=as.factor(train2$HardDrugs),
x=as.matrix(subset(train2, select=-HardDrugs)),
method = "knn",
tunegrid = tunegrid,
trControl=trControl,
metric = "Accuracy")
key <- toString(mtry)
accuracy[[key]] <- fit
}
trControl <- trainControl(method="repeatedcv", number=5, repeats=2)
accuracy <- list()
for (mtry in seq(2,20,2)){
tunegrid = expand.grid(.mtry = mtry)
fit <- train(y=as.factor(train2$HardDrugs),
x=as.matrix(subset(train2, select=-HardDrugs)),
method = "rf",
tunegrid = tunegrid,
trControl=trControl,
metric = "Accuracy")
key <- toString(mtry)
accuracy[[key]] <- fit
}
set.seed(100)
trControl <- trainControl(method="repeatedcv", number=5, repeats=2)
accuracy <- list()
for (mtry in seq(2,20,2)){
tunegrid = expand.grid(.mtry = mtry)
fit <- train(y=as.factor(train2$HardDrugs),
x=as.matrix(subset(train2, select=-HardDrugs)),
method = "rf",
tunegrid = tunegrid,
trControl=trControl,
metric = "Accuracy")
key <- toString(mtry)
accuracy[[key]] <- fit
}
set.seed(100)
trControl <- trainControl(method="repeatedcv", number=5, repeats=2)
accuracy <- list()
for (mtry in seq(2,20,2)){
tunegrid = expand.grid(.mtry = 1:10)
fit <- train(y=as.factor(train2$HardDrugs),
x=as.matrix(subset(train2, select=-HardDrugs)),
method = "rf",
tunegrid = tunegrid,
trControl=trControl,
metric = "Accuracy")
key <- toString(mtry)
accuracy[[key]] <- fit
}
set.seed(100)
trControl <- trainControl(method="repeatedcv", number=5, repeats=2)
accuracy <- list()
for (mtry in seq(2,20,2)){
fit <- train(y=as.factor(train2$HardDrugs),
x=as.matrix(subset(train2, select=-HardDrugs)),
method = "rf",
trControl=trControl,
metric = "Accuracy")
key <- toString(mtry)
accuracy[[key]] <- fit
}
trControl <- trainControl(method="repeatedcv", number=5, repeats=2)
accuracy <- list()
for (mtry in seq(2,20,2)){
fit <- train(HardDrugs~.,
data = train2,
method = "rf",
trControl=trControl,
metric = "Accuracy")
key <- toString(mtry)
accuracy[[key]] <- fit
}
trControl <- trainControl(method="repeatedcv", number=5, repeats=2)
mtry <- seq(2,20,2)
tunegrid <- expand.grid(.mtry = mtry)
fit <- train(HardDrugs~.,
data = train2,
method = "rf",
tuneGrid = tunegrid,
trControl=trControl,
metric = "Accuracy")
fit
mod_rf2 <- randomForest(form_full,train2,ntree=1000,mtry = 8)
rf2_ConfMat <- confusion_matrix(test2, test2$HardDrugs,mod_rf2)
rf2_misClassRate <- misclass(rf2_ConfMat)
paste("Misclassification Rate for RF Model with mtry 8: ")
mod_rf2 <- randomForest(form_full,train2,ntree=1000,mtry = 8)
rf2_ConfMat <- confusion_matrix(test2, test2$HardDrugs,mod_rf2)
rf2_misClassRate <- misclass(rf2_ConfMat)
paste("Misclassification Rate for RF Model with mtry 8: ", round(rf2_misClassRate,4))
mod_rf3 <- randomForest(form_full,train2,ntree=1000,mtry = 6)
rf3_ConfMat <- confusion_matrix(test2, test2$HardDrugs,mod_rf3)
rf3_misClassRate <- misclass(rf3_ConfMat)
paste("Misclassification Rate for RF Model with mtry 6: ", round(rf3_misClassRate,4))
getwd()
setwd("~/Desktop/Fall2022 Class Materials/STAT1261/FinalExam")
knitr::opts_chunk$set(echo = TRUE, cache=TRUE, out.width="60%")
library(tidyverse)
library(cluster)
salary_US0 = read_csv("salary.csv", show_col_types = FALSE)
salary_US1 <- salary_US0 %>% filter(`native-country`=="United-States")
View(salary_US0)
salary_US0 = read_csv("salary.csv", show_col_types = FALSE)
salary_US1 <- salary_US0 %>% filter(`native-country`=="United-States")
glimpse(salary_US1)
sum(is.na(salary_US1))
salary_US2 <- as.data.frame(unclass(salary_US1), stringsAsFactors=TRUE)
summary(salary_US2)
salary_US3 <- salary_US2 %>% select(-c(native.country,fnlwgt,education,relationship))
boxplot(salary~age,data=salary_US3,horizontal=T)
set.seed(99)
train_US <- sample_frac(salary_US3, 0.8, fac="salary") # Stratifies sampling
test_US <- setdiff(salary_US3, train_US)
library(rpart)
library(rpart.plot)
set.seed(99)
mod_tree <- rpart(salary~ ., data = train_US)
rpart.plot(mod_tree)
library(rpart)
library(rpart.plot)
set.seed(99)
mod_tree <- rpart(salary~ ., data = train_US)
rpart.plot(mod_tree)
library(randomForest)
set.seed(99)
set.seed(99)
form_tree <- as.formula(salary~ .)
mod_tree <- rpart(form_tree, data = train_US)
rpart.plot(mod_tree)
rpart.plot(mod_tree)
confusion_matrix <- test_US %>%
mutate(pred = predict(mod_tree, type = "class")) %>%
select(salary, pred) %>% table()
confusion_matrix <- test_US %>%
mutate(pred = predict(mod_tree, newdata = test_US, type = "class"), y=salary) %>%
select(salary, pred) %>% table()
confusion_matrix
dim(test_US)
misRate <- sum(diag(confusion_matrix))/sum(confusion_matrix)
paste("Misclassification Rate: ", misRate)
misRate <- 1 - sum(diag(confusion_matrix))/sum(confusion_matrix)
paste("Misclassification Rate: ", round(misRate,4))
rpart.plot(mod_tree)
rpart.plot(mod_tree)
library(randomForest)
set.seed(99)
form_rf <- as.formula(salary~ .)
mod_max <- model.matrix(form_rf, data = train_US)
rf_mod <- glmnet(mod_max, train_US$salary)
library(randomForest)
set.seed(99)
form_rf <- as.formula(salary~ .)
mod_max <- model.matrix(form_rf, data = train_US)
rf_mod <- glmnet(mod_max, train_US$salary)
set.seed(99)
form_rf <- as.formula(salary~ .)
rf_mod <- randomForest(form_rf, train_US)
confusion_rf <- test_US %>%
mutate(pred_rf = predict(rf_mod, newdata = test_US, type = "class"), y=salary) %>%
select(salary, pred_rf) %>% table()
confusion_rf <- test_US %>%
mutate(pred_rf = predict(rf_mod, newdata = test_US, type = "class"), y=salary) %>%
select(salary, pred_rf) %>% table()
confusion_rf
misRate_rf <- 1 - sum(diag(confusion_rf))/sum(confusion_rf)
paste("Random Forest Misclassification Rate: ", misRate_rf)
misRate_rf <- 1 - sum(diag(confusion_rf))/sum(confusion_rf)
paste("Random Forest Misclassification Rate: ", round(misRate_rf,4))
set.seed(99)
rf_mod2 <- randomForest(form_rf, train_US, ntree = 100, mtry = 10)
confusion_rf2 <- test_US %>%
mutate(pred_rf2 = predict(rf_mod2, newdata = test_US, type = "class"), y=salary) %>%
select(salary, pred_rf2) %>% table()
confusion_rf2
misRate_rf2 <- 1 - sum(diag(confusion_rf2))/sum(confusion_rf2)
paste("Random Forest Misclassification Rate: ", round(misRate_rf2,4))
names(salary_US3)
library(glmnet)
form_full <- as.formula("salary~age+workclass+education.num+
marital.status+occupation+race+sex+capital.gain+
capital.loss+hours.per.week")
set.seed(99)
predictors <- model.matrix(form_full, data = train_US)
cv.mod <- cv.glmnet(predictors,train_US$salary,nfolds = 5, family = "binomial", type.measure = "class")
cv.mod
plot(cv.mod)
mod_lr <- glmnet(predictors,train_US$salary,family="binomial", lambda = "lambda.lse")
mod_lr <- glmnet(predictors,train_US$salary,family="binomial", lambda = 0.005177)
logistic.misclassrate <- function(dataset, y, fit, form){
misclass_lr <- dataset %>%
mutate(pred.logistic = predict(fit, newx = model.matrix(form, data = dataset),
type = "class")) %>%
mutate(misclassify = ifelse(y != pred.logistic, 1,0)) %>%
summarize(misclass.rate = mean(misclassify))
return(misclass_lr$misclass.rate)
}
library(tibble)
importance(rf_mod) %>%
as.data.frame() %>%
rownames_to_column() %>%
arrange(desc(MeanDecreaseGini))
lr_misRate <- logistic.misclassrate(test_US,test_US$salary,mod_lr,form_full)
paste("Logistic Regression Misclassification Rate with lambda = 0.005177: ", lr_misRate)
lr_misRate <- logistic.misclassrate(test_US,test_US$salary,mod_lr,form_full)
paste("Logistic Regression Misclassification Rate with lambda = 0.005177: ", round(lr_misRate,4))
set.seed(99)
mod_lr2 <- glmnet(predictors, train_US$salary,family="binomial", lambda=0.000383)
lr_misRate2 <- logistic.misclassrate(test_US, test_US$salary,mod_lr2, form_full)
paste("Logistic Regression Misclassification Rate with lambda = 0.000383: ", round(lr_misRate2,4))
library(rpart)
library(rpart.plot)
set.seed(99)
form_tree <- as.formula(salary~ .)
mod_tree <- rpart(form_tree, data = train_US)
rpart.plot(mod_tree)
confusion_matrix <- test_US %>%
mutate(pred = predict(mod_tree, newdata = test_US, type = "class"), y=salary) %>%
select(salary, pred) %>% table()
confusion_matrix
misRate <- 1 - sum(diag(confusion_matrix))/sum(confusion_matrix)
paste("Misclassification Rate: ", round(misRate,4))
true_pos <- confusion_matrix[1,1] / sum(confusion_matrix[1,])
paste("True Positive Rate: ", true_pos)
true_neg <- confusion_matrix[2,2] / sum(confusion_matrix[2,])
paste("True Negative Rate: ", true_neg)
true_pos <- confusion_matrix[1,1] / sum(confusion_matrix[1,])
paste("True Positive Rate: ", round(true_pos,4))
true_neg <- confusion_matrix[2,2] / sum(confusion_matrix[2,])
paste("True Negative Rate: ", round(true_neg,4))
library(randomForest)
set.seed(99)
form_rf <- as.formula(salary~ .)
rf_mod <- randomForest(form_rf, train_US)
confusion_rf <- test_US %>%
mutate(pred_rf = predict(rf_mod, newdata = test_US, type = "class"), y=salary) %>%
select(salary, pred_rf) %>% table()
confusion_rf
misRate_rf <- 1 - sum(diag(confusion_rf))/sum(confusion_rf)
paste("Random Forest Misclassification Rate: ", round(misRate_rf,4))
rf_truePos <- confusion_rf[1,1] / sum(confusion_rf[1,])
paste("Random Forest True Positive: ", round(rf_truePos,4))
rf_trueNeg <- confusion_rf[2,2] / sum(confusion_rf[2,])
paste("Random Forest True Negative: ", round(rf_trueNeg,4))
set.seed(99)
rf_mod2 <- randomForest(form_rf, train_US, ntree = 100, mtry = 10)
confusion_rf2 <- test_US %>%
mutate(pred_rf2 = predict(rf_mod2, newdata = test_US, type = "class"), y=salary) %>%
select(salary, pred_rf2) %>% table()
confusion_rf2
misRate_rf2 <- 1 - sum(diag(confusion_rf2))/sum(confusion_rf2)
paste("Random Forest Misclassification Rate: ", round(misRate_rf2,4))
rf_truePos2 <- confusion_rf2[1,1] / sum(confusion_rf2[1,])
paste("Random Forest w/ mtry+ntree True Positive: ", round(rf_truePos2,4))
rf_trueNeg2 <- confusion_rf2[2,2] / sum(confusion_rf2[2,])
paste("Random Forest w/ mtry+ntree True Negative: ", round(rf_trueNeg2,4))
library(tibble)
importance(rf_mod) %>%
as.data.frame() %>%
rownames_to_column() %>%
arrange(desc(MeanDecreaseGini))
names(salary_US3)
library(glmnet)
form_full <- as.formula("salary~age+workclass+education.num+
marital.status+occupation+race+sex+capital.gain+
capital.loss+hours.per.week")
set.seed(99)
predictors <- model.matrix(form_full, data = train_US)
cv.mod <- cv.glmnet(predictors,train_US$salary,nfolds = 5, family = "binomial", type.measure = "class")
cv.mod
plot(cv.mod)
mod_lr <- glmnet(predictors,train_US$salary,family="binomial", lambda = 0.005177)
logistic.misclassrate <- function(dataset, y, fit, form){
misclass_lr <- dataset %>%
mutate(pred.logistic = predict(fit, newx = model.matrix(form, data = dataset),
type = "class")) %>%
mutate(misclassify = ifelse(y != pred.logistic, 1,0)) %>%
summarize(misclass.rate = mean(misclassify))
return(misclass_lr$misclass.rate)
}
lr_misRate <- logistic.misclassrate(test_US,test_US$salary,mod_lr,form_full)
paste("Logistic Regression Misclassification Rate with lambda = 0.005177: ", round(lr_misRate,4))
set.seed(99)
mod_lr2 <- glmnet(predictors, train_US$salary,family="binomial", lambda=0.000383)
lr_misRate2 <- logistic.misclassrate(test_US, test_US$salary,mod_lr2, form_full)
paste("Logistic Regression Misclassification Rate with lambda = 0.000383: ", round(lr_misRate2,4))
happiness_0 = read_csv("happiness_2018.csv", show_col_types = FALSE)
glimpse(happiness_0)
sum(is.na(happiness_0))
happiness_1 = happiness_0 %>%
mutate(Corruption = as.numeric(`Perceptions of corruption`))
sum(is.na(happiness_1$Corruption))
happiness_1[is.na(happiness_1$Corruption),] %>% select(c(`Country or region`,Corruption))
happiness_2 = happiness_1 %>% drop_na()
dim(happiness_2)
happiness_3 = happiness_2 %>%
select(-c(`Overall rank`, `Country or region`,`Perceptions of corruption`))
head(happiness_3,3)
names(happiness_3)
names(happiness_3) <- c("Score", "GDPP", "SocialSupport","LifeExp", "Freedom", "Generosity","Corruption")
head(happiness_3,3)
pc.happiness <- prcomp(happiness_3, scale = TRUE)
pc.happiness
pc.var <- pc.happiness$sdev^2
pve <- pc.var/sum(pc.var)
pve[1:5]
pc.var <- pc.happiness$sdev^2
pve <- pc.var/sum(pc.var)
paste("PVE for the first 3 Principal Components: ", pve[1:3])
library(ggplot2)
PC = 1:10
myPC <- data.frame(PC, pve)
library(ggplot2)
PC = 1:7
myPC <- data.frame(PC, pve)
ggplot(data=myPC, aes(x=PC,y=pve))+
geom_line(color = "black") +
labs(x="Principal Components",y="PVE") +
scale_x_continuous(breaks = 1:7)
library(ggplot2)
PC = 1:7
myPC <- data.frame(PC, pve)
ggplot(data=myPC, mapping = aes(x=PC,y=pve))+
geom_line(color = "black") +
geom_point(color = "blue", cex = 2)
library(ggplot2)
PC = 1:7
myPC <- data.frame(PC, pve)
ggplot(data=myPC, mapping = aes(x=PC,y=pve))+
geom_line(color = "black") +
geom_point(color = "blue", cex = 2)+
labs(x="Principal Components",y="PVE") +
scale_x_continuous(breaks = 1:7)
install.packages(ggplot2)
install.packages("ggplo2")
install.packages("ggplot2")
install.packages("ggplot2")
library(ggplot2)
PC = 1:7
myPC <- data.frame(PC, pve)
ggplot(data=myPC, mapping = aes(x=PC,y=pve))+
geom_line(color = "black") +
geom_point(color = "blue", cex = 2)+
labs(x="Principal Components",y="PVE") +
scale_x_continuous(breaks = 1:7)
dev.off
dev.off()
library(ggplot2)
PC = 1:7
myPC <- data.frame(PC, pve)
ggplot(data=myPC, mapping = aes(x=PC,y=pve))+
geom_line(color = "black") +
geom_point(color = "blue", cex = 2)+
labs(x="Principal Components",y="PVE") +
scale_x_continuous(breaks = 1:7)
library(ggplot2)
PC = 1:7
myPC <- data.frame(PC, pve)
ggplot(data=myPC, mapping = aes(x=PC,y=pve))+
geom_line(color = "black") +
geom_point(color = "blue", cex = 2)+
geom_point(aes(x=3,y=pve[3]), alpha = 0.5, color = "orange", cex = 3) +
labs(x="Principal Components",y="PVE") +
scale_x_continuous(breaks = 1:7)
library(ggplot2)
PC = 1:7
myPC <- data.frame(PC, pve)
ggplot(data=myPC, mapping = aes(x=PC,y=pve))+
geom_line(color = "black") +
geom_point(aes(x=3,y=pve[3]), alpha = 0.5, color = "orange", cex = 3) +
geom_point(color = "blue", cex = 2)+
labs(x="Principal Components",y="PVE") +
scale_x_continuous(breaks = 1:7)
library(ggplot2)
PC = 1:7
myPC <- data.frame(PC, pve)
ggplot(data=myPC, mapping = aes(x=PC,y=pve))+
geom_line(color = "black") +
geom_point(aes(x=3,y=pve[3]), alpha = 0.5, color = "orange", cex = 4) +
geom_point(color = "blue", cex = 2)+
labs(x="Principal Components",y="PVE") +
scale_x_continuous(breaks = 1:7)
library(ggplot2)
PC = 1:7
myPC <- data.frame(PC, pve)
ggplot(data=myPC, mapping = aes(x=PC,y=pve))+
geom_line(color = "black") +
geom_point(aes(x=3,y=pve[3]), alpha = 0.3, color = "orange", cex = 4) +
geom_point(color = "blue", cex = 2)+
labs(x="Principal Components",y="PVE") +
scale_x_continuous(breaks = 1:7)
library(ggplot2)
PC = 1:7
myPC <- data.frame(PC, pve)
ggplot(data=myPC, mapping = aes(x=PC,y=pve))+
geom_line(color = "black") +
geom_point(color = "blue", cex = 2)+
geom_point(aes(x=3,y=pve[3]), alpha = 0.3, color = "orange", cex = 4) +
labs(x="Principal Components",y="PVE") +
scale_x_continuous(breaks = 1:7)
library(ggplot2)
PC = 1:7
myPC <- data.frame(PC, pve)
ggplot(data=myPC, mapping = aes(x=PC,y=pve))+
geom_line(color = "black") +
geom_point(color = "blue", cex = 2)+
geom_point(aes(x=3,y=pve[3]), alpha = 0.1, color = "orange", cex = 4) +
labs(x="Principal Components",y="PVE") +
scale_x_continuous(breaks = 1:7)
ggplot(data=myPC, aes(x=PC,y=cumsum(pve))) +
geom_hline(aes(yintercept = 0.9), lty = 3, color = "blue", lwd = 1)+
geom_line(color="black")+
geom_point(color = "orange", cex = 2) +
labs(title="Cumulative PVE for Principal Components 1-7", x="Principal Components", y="Cumulative PVE")+
scale_x_continuous(breaks=1:7)
PC12 <- pc.happiness %>%
select(PC1, PC2) %>%
ggplot(aes(x=PC1,y=PC2)) +
geom_point()
pc_tibble <- pc.happiness %>% as.tibble()
pc_tibble <- pc.happiness %>% as_tibble()
pc.happiness
pc.happiness$rotation[1:2]
pc.happiness$rotation[,1:2]
data.frame(pc.happiness$rotation[,1:2])
PC12 <- data.frame(pc.happiness$rotation[,1:2])
PC12 %>%
ggplot(aes(x=PC1,y=PC2))+
geom_point()
happiness_4 <- scale(happiness_3)
library(factoextra)
fviz_nbclust(happiness_4, kmeans, method="gap_stat")
set.seed(99)
km_mod <- kmeans(x=happiness_4,centers=3)
PC12_cluster <- PC12 %>% mutate(cluster=factor(km_mod$cluster))
km_mod
happiness_3 %>%
hist(GDPP)
head(happiness_3)
hist(happiness_3$GDPP)
hist(happiness_3$GDPP)
hist(happiness_3$GDPP)
hist(happiness_3$Freedom)
hist(happiness_3$Corruption)
dim(happiness_3)
install.packages("GGally")
library(GGally)
ggpairs(happiness_3)
dim(pc.happiness)
PC12 <- data.frame(pc.happiness$rotation[,1:2])
PC12 %>%
ggplot(aes(x=PC1,y=PC2))+
geom_point()
happiness_4 <- scale(happiness_3)
library(factoextra)
fviz_nbclust(happiness_4, kmeans, method="gap_stat")
print("Optimal Number of clusters is 3!")
PC12 <- data.frame(pc.happiness$x[,1:2])
PC12 %>%
ggplot(aes(x=PC1,y=PC2))+
geom_point()
dim(PC12)
set.seed(99)
km_mod <- kmeans(x=happiness_4,centers=3)
PC12_cluster <- PC12 %>% mutate(cluster=factor(km_mod$cluster))
PC12_cluster %>%
select(PC1,PC2,cluster) %>%
ggplot(aes(x=PC1,y=PC2,color=cluster)) +
geom_point()
PC12_cluster <- PC12_cluster %>% mutate(`Country or Region` = happiness_2$`Country or region`)
cluster1 <- PC12_cluster[PC12_cluster$cluster == 1]
head(PC12_cluster)
cluster1
cluster1 <- select(PC12_cluster$cluster == 1)
cluster1 <- which(PC12_cluster$cluster == 1)
cluster1
cluster1 <- PC12_cluster[which(PC12_cluster$cluster == 1),]
cluster1$`Country or Region`
length(cluster1)
cluster1
dim(cluster1)
fviz_cluster(km_mod, data=PC12, xlab="PC1",ylab="PC2",ellipse.type="convex",ggtheme=theme_minimal(),main="K-means")
ggplot(data=salary_US3,mapping=aes(sex,salary))+
geom_bin2d()
head(salary_US3)
ggplot(data=salary_US3,mapping=aes(x=capital.gain,y=..density..))+
geom_freqpoly(mapping=aes(color=salary))
ggplot(data=salary_US3,mapping=aes(x=capital.gain,y=..density..))+
geom_freqpoly(mapping=aes(color=salary), binwidth = 500)
ggplot(data=salary_US3,mapping=aes(x=capital.gain,y=..density..))+
geom_freqpoly(mapping=aes(color=salary), binwidth = 10000)
ggplot(data=salary_US3,mapping=aes(x=capital.gain,y=..density..))+
geom_freqpoly(mapping=aes(color=salary), binwidth = 6000)
boxplot(salary~age,data=salary_US3)
salary_factor <- salary_US3 %>% mutate(cluster=factor(salary))
boxplot(cluster~age,data=salary_factor)
ggplot(data=salary_US3,mapping=aes(x=salary,y=age)) +
geom_boxplot()
ggplot(data=salary_US3,mapping=aes(x=capital.gain))+
geom_freqpoly(mapping=aes(color=salary), binwidth = 6000)
rpart.plot(mod_tree)
rpart.plot(mod_tree)
dim(test_US)
